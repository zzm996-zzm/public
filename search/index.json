[{"content":"优先队列 绪论 优先队列也可以称之为堆，分为大根堆和小根堆。堆的用处很多，最常见的也就是所谓的堆排序，可以发现也是利用了树的思想去做的。\n也许用图表达更合适。\n image \n 堆：符合以下两个条件之一的完全二叉树：\n  根节点的值 ≥ 子节点的值，这样的堆被称之为最大堆，或大顶堆；\n  根节点的值 ≤ 子节点的值，这样的堆被称之为最小堆，或小顶堆。\n  image \n明确的基础的概念之后可以思考一下堆排序。首先将数列构建成一个大根堆，按照性质大根堆的堆顶一定是数组中最大的元素，所以我们可以每次将堆顶的元素换到最后面去，然后重新构建一次大根堆，以此类推就会得到一个排序好的数组。\n初始化堆 首先谈谈如何初始化堆。\n 情况1: 一个一个插入元素，依次构建堆 情况2: 将一个数组构建堆  我们可以从下标1开始当做根节点，那么数组的长度为N+1（N为原数组长度）设根节点为i，那么 公式可以得出\n i = 1;\n  left = i*2;\n  right = left+1;\n 不妨思考一下这两种情况的复杂度，空间复杂度来说可以直接给出结论，是 O(1),基本是在原数组构建完全二叉树。那么实际复杂度呢？\n第一种情况 思考一个这样的情况（最坏的情况，大根堆），每次插入的元素都是当前序列中最大的元素,由于是数组，那么每次插入都是append在末端。那么会造成什么样的情况呢？\n当前节点会沿着树的拓扑一直往上浮，树的度为M，那么树的高度是log M，不妨称之为N，那么意味着当前会在树结构中上浮N次。那么参考这张图\n image \n此时树的高度为3，底层每个节点往上浮动的数量都是当节点的深度,所以在高度为3的的堆每次插入节点最坏的情况就是28，N=13，logn=3~4 最大上浮次数是28（不妨先定义为push的操作是O(logn)）\n所以我们可以得出每次插入节点上浮的复杂度O(n*logn)\n第二种情况 思考一下，如果初始化就是一个数组的情况下，我们会怎么构建这个堆？莫非还是一个个遍历插入吗？显然不会这样做，会有更聪明的办法。\n参考第一种情况，既然自底向上上浮不好，那么下沉呢？我们要的结果是降低复杂度，所以思考一下树的结构会发现，树的深度越深，那么节点的数量越多，这些结果都是上浮那么复杂度会很高，但是如果是下沉，那么最深的节点已经在最深处了，就不需要下沉了。\n参考这段代码\nfunc Init(h Interface) { // heapify \tn := h.Len() //h认为是一个数组 \tfor i := n/2 - 1; i \u0026gt;= 0; i-- { down(h, i, n) //down 下沉 \t} } 看看他的语义，获取数组的长度为n，for循环中每次都下沉，但是i是 n/2-1。所以真正的优化就是在这，参考这张图。\n使用二分的思想。先从从树的中间往下下沉（自底向上的下沉），可以发现，根节点无需下沉。每个节点下沉的大小刚好是他的高度。\n image \n看看结果，构建一个堆的复杂度为O(n),达到了一个还不错的线性复杂度。\n分析代码 说了那么多理论不贴代码怎么行，不过golang有提供heap的package，这里就贴一下源码就行。然后解释解释。\n h理解为一个数组，有3个方法。Less作比较的，swap交换元素 Len获取当前元素大小\n 两段最重要的代码\nup顾名思义上浮，按照之前的公式，j为当前节点，首先获取他的父亲节点\n j-1/2 得到父亲节点的下标\n 如果当前节点大于parent，那么交换，以此类推直到达到合适的位置或者到了根节点。此时上浮结束。时间复杂度为O(logn),基本就是树的高度了。\n image \n顾名思义这段代码是下沉的代码。看起来还挺多的，但是仔细思考一下还是很简单的。\n先获取当前节点的左孩子 j1，先判断是否大于数组长度了，即已经到尾巴了，还会判断数据是否溢出（想的周到啊宝）。之后再判断左孩子是否大于右孩子，如果是则直接和parent比较，如果大于那么parent下沉，继续和左右孩子比较，交换，直到合适的位置。\n复杂度为 O(logn)\n思考一下为什么下沉还有返回一个bool？\n image \npush操作  image \n直接push到数组尾部，然后上浮即可，复杂度同up\npop操作 其实删除操作就比较有意思，在我的印象里，无论是什么树，只要这棵树有一定特性，那么删除就一定不会简单（实名diss红黑）。\n可以看看具体代码，还是很简单的，将堆顶的元素删除，从数组末尾换一个新节点上来，然后下沉到对应的位置即可\n image \n但是还有一段代码可以瞧瞧，remove和pop不一样，pop是直接弹出堆顶，remove是删除堆中指定某个位置的元素。\n我们瞧瞧具体代码，如果是数组末尾，则直接pop删除掉就行了，如果不是，则将数组末尾的值和需要删除的节点调换位置，然后判断是否需要下沉！，如果不需要下沉则上浮。这就是为什么down的需要返回一个bool的原因。\n image \nFix操作 fix操作类似update，修改堆中元素的值，然后判断是否需要浮动\n image \n谈谈实际应用 除了堆排序我们可以看看在实际应用会这么使用堆这个数据结构\n image \n直接给出答案，首先初始化堆，然后一次pop，当pop到第k次的时候就是最大第k个。\n再来看看第二题\n image \n这这道题我们思考一下合并3个链表，怎么用到堆呢？平时是不是都是数组？\n其实思路也很简单，把链表的头当做单独的元素构建堆。比如此时构建的堆是\n【1，1，2】\n每次pop元素的时候把当前堆顶指向下一个元素，然后重置堆。\n比如pop 1 这个元素 ，那么把堆顶1变成他的next 4 重置堆就变成了\n【1，2，4】\n看到这里我相信已经明白了具体思路了。\n","date":"2021-11-01T00:00:00Z","image":"https://zzm-1300642547.file.myqcloud.com/blog/images/datastruct/wallhaven-rdql81.jpg","permalink":"https://example.com/p/datastruct/","title":"优先队列"},{"content":"AVL树的核心概念 回到二叉搜索树(BST)他的优点显而易见是查询和插入都相对来说非常的高效，在较为好的情况下可以做到都是logn的操作，n对应为树的size。当然这说的是最好的情况下，如果说最坏的情况，会退化成一个链表，所以延伸出了AVL树，之后还有一个红黑树。\nAVL的基本概念 AVL的基本概念是一个根节点（每一个子节点也可以看做是一个根节点），的左子树和右子树的高度相差不超过2。看看下面这个图\n image \n例如左图根节点4，它的左节点3的高度为0，右节点没有索引位-1，高度差的概念是\n** 左子节点高度 - 右子节点的高度 = 0 - (-1） = 1**\n根节点2，它的左节点1的高度为0，右节点4的高度为1 所以 0 - 1 = - 1\n既然知道了AVL的定义，那么查看右图显而易见。对于根节点7的左子树高度是3（2，4，5 | 2，4，3），右子树高度为1（8）\n3 - 1 = 2 不符合AVL的定义\nAVL的接口 AVL树查询可以完美继承BST，所以需要扩展的接口是插入和删除两个接口\n插入接口 首先参考这个图，在插入节点3之前是平衡的AVL，但是插入节点3之后，就失去平衡了，失去平衡的节点就是节点6。\n image \n此时此刻就需要旋转，变成如下这样\n image \n此时此刻就平衡了。没错AVL就是每次插入判断是否高度失衡。如果失去平衡则选择。如何选择失去平衡的节点？参考失衡的图，4没有失去平衡，但是6的左节点为2，右节点为0，这就是失去平衡了。所以旋转点就是根节点6！\n旋转的4种情况 旋转的情况在邓公的书中有很好的描述\n单旋，分左右\n image \n双旋\n image \n删除接口 删除的情况和插入很像，使用BST的删除接口，删除之后自底向上判断是否失平衡。仔细回想一下，插入一个节点如果失去平衡，在旋转一次之后会恢复平衡，父节点一直沿着根节点的高度不会发生变化，所以只需要旋转一次即可，但是删除操作是删除一个节点，旋转之后高度会-1。缺失高度的情况会沿着链路一直往上蔓延。\n但是解决办法就是 当旋转完之后判断父节点是否依旧失平衡\npackage datastructure type AVLInterface interface { } type AVL struct { BST } func NewAVL(data Data) *AVL { avl := \u0026amp;AVL{*NewBST(data)} avl.data = data return avl } func (avl *AVL) InsertAVL(data Data) *BinNode { x := avl.Insert(data) //BST insert \t//从x的父节点逐层检查是否高度失衡 \tfor i := x.parent; i != nil; i = i.parent { if !AvlBalanced(i) { //如果失衡了 \t//旋转平衡 \t*avl.FromParentTo(i) = RotateAt(TallerChild(TallerChild(i))) break } UpdateHeight(i) } return x } func (avl *AVL) RemoveAVL(data Data) bool { node := searchr(\u0026amp;avl.root, data) if node == nil { return false } hot := \u0026amp;BinNode{} removeAt(node, \u0026amp;hot) for i := hot; i != nil; i = i.parent { if !AvlBalanced(i) { //旋转平衡 \t*avl.FromParentTo(i) = RotateAt(TallerChild(TallerChild(i))) } UpdateHeight(i) } return true } func (avl *AVL) FromParentTo(node *BinNode) **BinNode { if IsRoot(node) { return \u0026amp;avl.root } else if IsLChild(node) { return \u0026amp;node.parent.left } else { return \u0026amp;node.parent.right } } func Balanced(avl *BinNode) bool { return Stature(avl.left) == Stature(avl.right) } func BalFac(avl *BinNode) int { return Stature(avl.left) - Stature(avl.right) } func AvlBalanced(avl *BinNode) bool { return BalFac(avl) \u0026gt; -2 \u0026amp;\u0026amp; BalFac(avl) \u0026lt; 2 } func (avl *AVL) IsAVL(node *BinNode) { if node == nil { // fmt.Println(\u0026#34;是一颗完美的AVL!\u0026#34;) \treturn } if !AvlBalanced(node) { panic(\u0026#34;不是平衡树\u0026#34;) } avl.IsAVL(node.left) avl.IsAVL(node.right) } ","date":"2021-10-25T00:00:00Z","image":"https://zzm-1300642547.file.myqcloud.com/blog/images/datastruct/avl.png","permalink":"https://example.com/p/avl/","title":"AVL"},{"content":"虚拟地址翻译  image-20210911095952199 \n image-20210911091039316 \n这是一张虚拟地址转换成物理地址的流程图，cpu解析一个虚拟地址 解析出VPN和VPO\n VPO从图中可以看出对应的是PPO 也就是图中的后12位就是对应的物理真实地址的12位\nVPN和VPO与真实系统中页的大小息息相关，如果页的大小为4KB 那么就是 2^n = 4KB n = 12\n所以VPO = 12 剩下的地址是 VPN\n VPN对应着TLB表，这张表的作用用于是缓存的PPN，PPN是真实物理地址的高40位（图中可知），所以就是一个缓存表，TLB表的两个很重要的属性\n TLBI：TLB表的索引 TLBT: TLB表的标记  如图：\n image-20210911100527106 \n假设TLB是四路组相连，每组有4个条目。一共是16个条目。\n那么可以得到的是 4 = 2^n n=2 。那么VPN的低2位就是TLBI，剩下的就是TLBT\n根据如上参数，假设虚拟地址是 0x0f3\n 0000 1111 0011\n假设VPN是 00001111\nTLBT = 000011\nTLBI = 11\n 对应图中的最后一组标记位为 0x3,如果有效位是1 ，则表示命中 获取到的PPN 是 0xD\n接着上图，如果在TLB表中命中，则返回PPN 然后与 VPO（PPO），如果没有命中则去拿着VPN去页表中获取PPN，然后缓存到TLB中，然后把PPN和VPO(PPO) 结合起来就是真实的物理地址。然后通过L1cache，如果L1cache没有命中则一次去L2,L3，主存中获取数据再返回给CPU，这个就是一个虚拟地址翻译成物理地址，并获取数据的流程\n","date":"2021-09-12T00:00:00Z","image":"https://zzm-1300642547.file.myqcloud.com/blog/images/os/233154-15779791144569.jpg","permalink":"https://example.com/p/virtualaddress/","title":"虚拟地址翻译"},{"content":"多级页表如何节约内存 前言 假设虚拟地址空间为32位（4GB内存）每个页表条目是4B（字节），然后每一个页的大小是4KB，那么对应起来就是，如果此时只有一级页表。那么就是 4GB / 4KB = 1M 需要1M个页表，然后由于每个页表条目是4B，那么一个进程的需要常驻使用的页表内存是 1M * 4B = 4MB 内存空间。 每个进程都有一个这样的4MB占用，所以开销也是不小的\n换成多级级页表 ，假设一级页表映射的是4MB，然后二级页表映射4KB 是4GB /4MB = 1K 需要1k个一级页表条目，然后每个条目的内容对应一个二级页表，每个二级页表有 4MB / 4KB = 1K 个页表条目，二级页表里面的内容才是真实的物理地址。这样可以计算出一个公式\n1024 * 4 + 1024 * 1024 * 4 = 4.004MB 虽然看起来还大了一点，不过实际上 只有1级页表才需要常驻内存\n其实可以想想局部性原理\n如何节约内存 二级页表可以不存在 4G的虚拟地址需要的页表是1M个 需要4M的空间，换成二级页表（2个页表）只有就变成了 4GB/4MB = 1K 个一级页表，然后每个二级页表里面存的才是真正的PPN。\n由于程序的一级列表需要常驻内存，如果二级页表只有20%被使用，那么就是\n1024 * 4 + 0.2 * 1024 * 1024 * 4 = 0.8MB常驻内存 比之前的4MB小了很多\n那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在主存中的页表承担的职责是将虚拟地址翻译成物理地址；假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有1M个页表项来映射，而二级页表则最少只需要1K个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。\n二级页表可以不在主存 没有被使用到的二级列表会存在磁盘，在需要的时候会调度到主存中缓存。\n总结 我们把二级页表再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。\n回头想想，这么大幅度地解决内存空间，我们失去了什么呢？计算机的很多问题无外乎就是时间换空间和空间换时间了，而多级页表就是典型的时间换空间的例子了，动态创建二级页表、调入和调出二级页表都是需要花费额外时间的，远没有不分级的页表来的直接；而我们也仅仅是利用局部性原理让这个额外时间开销降得比较低了而已。\n","date":"2021-09-11T00:00:00Z","image":"https://zzm-1300642547.file.myqcloud.com/blog/images/os/234958-160502339805f5.jpg","permalink":"https://example.com/p/pagetable/","title":"多级页表"},{"content":"Mutex是如何实现的（2） 之前看了Mutex的第一版实现，比较简单，一个flag用来判断是否获取到了锁，其他的goroutine排队获取锁，如果换做是我，我能想到的就是第一版的实现。或许还会思考接下来的goroutine公平一点，不是排队获取锁。\n接着看第二版实现，给新的goroutine一些机会，总结来说就是新创建的goroutine肯定在这个时刻是cpu在运行的，所以新的goroutine能拿到锁的话就减少了一些切换的时间，可以在一定程度上提升效率。\n给新人机会 type Mutex struct { state int32 sema uint32 } const ( mutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked //初始值 1  mutexWoken //初始值 2  mutexWaiterShift = iota //初始值 2  ) 上面定义了一些常量，mutexLocked 表示是否拿到了锁，mutexWoken表示是否是被Unlock唤醒的，mutexWaiterShift 表示还有多少goroutine在等待获取锁，这些状态都是用state这一个int32位的字段去表示的，使用的是位表示，比如最低的1位表示mutexLocked，低位的第二位表示mutexWoken，其他的表示mutexWaiterShift。\n其实想看懂第二版就需要对位操作有一定的认识，下面我会详细的解释代码中位操作的含义。\n image-20210727142702392 \nLock func (m *Mutex) Lock() { // Fast path: 幸运case，能够直接获取到锁  if atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) { return } awoke := false for { old := m.state new := old | mutexLocked // 新状态加锁，希望这次能抢到锁  if old\u0026amp;mutexLocked != 0 { //如果被唤醒之后 old拿到的值 xxxx0 那么 xxxx0 \u0026amp; 00001 == 0  new = old + 1\u0026lt;\u0026lt;mutexWaiterShift //等待者数量加一  } if awoke { // goroutine是被唤醒的，  // 新状态清除唤醒标志  new \u0026amp;^= mutexWoken } if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) {//设置新状态  if old\u0026amp;mutexLocked == 0 { // 锁原状态未加锁  break } runtime.Semacquire(\u0026amp;m.sema) // 请求信号量  awoke = true } } } 首先还是有一个幸运case，如果cas操作设置state的时候可以直接成功，那么证明此时锁没有被占用，抢到锁的goroutine直接return去执行临界区的代码。如果没有抢到锁会进入for循环，首先awoke我们不管，直接看for循环里面的代码\n 看完unlock再去看awoke，unlock也比较复杂\n 情况1：拿到当前state的状态（old），直接使用 | 把new（state）的最低位设置位1，表示希望拿到锁。接着进入判断，如果之前拿到的old的最低位就是1，那么直接等待者+1，然后设置新的状态，并继续阻塞。\n情况2： 如果old的mutexlockd位是0，那么使用cas操作把new设置为新的state并break直接返回，表示当前goroutine拿到了锁，可以继续执行临界区的代码。\n 为什么需要cas操作，在这里再解释一下，如果把new设置成state的时候，其他goroutine也在执行这块的逻辑，如果比其他goroutine慢了一步，那么就会造成有多个2个或者多个goroutine break了。就同时执行临界区代码了。所以cas操作是锁的精髓\n Unlock func (m *Mutex) Unlock() { // Fast path: drop lock bit.  new := atomic.AddInt32(\u0026amp;m.state, -mutexLocked) //去掉锁标志  if (new+mutexLocked)\u0026amp;mutexLocked == 0 { //本来就没有加锁  panic(\u0026#34;sync: unlock of unlocked mutex\u0026#34;) } old := new for { if old\u0026gt;\u0026gt;mutexWaiterShift == 0 || old\u0026amp;(mutexLocked|mutexWoken) != 0 { // 没有等待者，或者有唤醒的waiter，或者锁原来已加锁  return } new = (old - 1\u0026lt;\u0026lt;mutexWaiterShift) | mutexWoken // 新状态，准备唤醒goroutine，并设置唤醒标志  if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { runtime.Semrelease(\u0026amp;m.sema) return } old = m.state } } 首先cas操作，把state-1，意思就是锁标志位=0，然后判断之前是否是加锁状态，如果之前没有加锁直接解锁会panic，这点要注意。\n然后进入for循环，第一个if有2个情况。\n**情况1：**之前注释中标记了，mutexWaiterShift是==2，意思就是32位的int中，高30位是mutexWaiterShift，把低2位移除之后如果是0，那么意味着没有等待者了可以直接返回，解锁成功。\n情况2： **mutexLocked | mutexWoken == 01 | 10 = 11 ** ，使用old去\u0026amp;的话，old \u0026amp; 0011，检查解锁后是否为唤醒和加锁状态。如果结果不为 0，证明还有其他协程将 state 设置为唤醒或加锁状态，释放锁。\n 情况2可以这样理解，在unlock的第一句就直接使用cas把state mutexlocked的状态改成0了，所有如果此时有新开的gorouine是可以直接获取到锁的，老的goroutine在阻塞中没有被唤醒。这就是给新人机会\u0026hellip;，如果没有新开的goroutine那么判断mutexWoken是否为1，如果为1则表示有被唤醒的goroutine，直接解锁成功\n 如果没有走进上面的if，那么会把等待的mutexWaiterShift -1，然后把mutexWoken设置为1，使用cas操作把新状态设置进去，然后唤醒其他goroutine，return掉，表示解锁成功。如果在执行cas的过程中发现state被其他goroutine改掉了，那么continue，重新来一遍。\n 其实我之前对mutexWoken还不是很理解，但是之后我想通了，我是这么想的\u0026hellip; 如果unlock把woken设置为1 唤醒其他goroutine之后，此时有新的goroutine进来的，新进来的awoke是false，是没有办法把woken置为0的，然后新的goroutine执行的又比较快，在其他goroutine被阻塞之前就释放了锁，那么条件old\u0026amp;(mutexLocked|mutexWoken) != 0 就会通过\n 总结 其实第二版理解起来也是稍微有点困难，我个人去看比较容易，但是用自己的话总结成博客就是一种锻炼了。下一篇就是第三版了，多给些机会，和第四版 解决饥饿问题.\n","date":"2021-06-13T00:00:00Z","image":"https://zzm-1300642547.file.myqcloud.com/blog/images/golang/221956-16033763963867.png","permalink":"https://example.com/p/mutex2/","title":"Mutex演进（2）"},{"content":"Mutex是如何实现的（1） 之前有看一本书上面写了mutex是如何实现的，使用大家都会用，无非就是Lock和Unlock，实现的是Locker接口。在此记录一下Mutex从第一版到现在最新版本是如何实现和演变的。（go 1.16）\n什么是Mutex 互斥锁是并发控制的一个手段，为了避免竞争而建立的并发机制，在并发编程中，如果程序中的一部分会被并发的访问或者修改，那么我们就应该考虑使用mutex去保护起来，这部分被保护的区域就是 临界区\nMutex的使用很简单，就像下面这样\nvar mu sync.Mutex count := 0 go func() { mu.Lock() count += 1 //临界区  mu.Unlock() }() 这里我摘抄一下网上的图片\n image-20210726190116730 \n最初的Mutex 介绍完之后就直接看看第一版的Mutex代码，初版的代码只有一个flag表示锁是否被持有，实现也很简单，只需要搞懂原子操作的代码就能看懂（cas），如果flag=1就表示被持有了，如果是0那么锁就会被goroutine们去竞争，抢到的goroutine就会把mutex的flag设置为1，然后继续执行临界区的代码。\n // CAS操作，当时还没有抽象出atomic包 func cas(val *int32, old, new int32) bool func semacquire(*int32) //阻塞 func semrelease(*int32) //唤醒 // 互斥锁的结构，包含两个字段 type Mutex struct { key int32 // 锁是否被持有的标识 sema int32 // 信号量专用，用以阻塞/唤醒goroutine } // 保证成功在val上增加delta的值 func xadd(val *int32, delta int32) (new int32) { for { v := *val //保存v的值 if cas(val, v, v+delta) { //cas操作，比较val和之前保存的v是否有变更 如果没有变更则把val设置为新的值 return v + delta } } panic(\u0026quot;unreached\u0026quot;) } // 请求锁 func (m *Mutex) Lock() { if xadd(\u0026amp;m.key, 1) == 1 { //标识加1，如果等于1，成功获取到锁 return } semacquire(\u0026amp;m.sema) // 否则阻塞等待 } func (m *Mutex) Unlock() { if xadd(\u0026amp;m.key, -1) == 0 { // 将标识减去1，如果等于0，则没有其它等待者 return } semrelease(\u0026amp;m.sema) // 唤醒其它阻塞的goroutine } 从第一版的mutex可以看出来，如果有10个goroutine去竞争，那么当其中一个goroutine竞争到的时候会把flag加1，如果加1之后==1那么意味着之前是0，表示没有goroutine抢到了锁，那么直接return去执行临界区的代码。当临界区的代码执行完毕之后会执行Unlock，没有抢到锁的goroutine会被\n我们看看unlock的逻辑，会调用xadd函数，把flag-1，此时flag应该是9，证明还有其他等待者，所有直接唤醒等待队列中的goroutine，由此可以看出，唤醒的之后是没有抢锁这个操作的，其他goroutine会直接回到lock中被唤醒然后返回，锁会唤醒队列中的第一个成员。\n总结 其实最后可以看出，第一版中有很多缺点，比如只有第一次会抢锁，其他的goroutine只能排队，如果来了新人也只能排队。此时此刻刚好启动一个goroutine，cpu正在运行它，如果这个时候他能直接抢到锁那会在一定程度上节约时间。下一篇记录第二版mutex是如何实现的\n","date":"2021-06-12T00:00:00Z","image":"https://zzm-1300642547.file.myqcloud.com/blog/images/golang/221956-16033763963867.png","permalink":"https://example.com/p/mutex1/","title":"Mutex演进（1）"}]