<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>golang on 张志明</title>
    <link>https://example.com/tags/golang/</link>
    <description>Recent content in golang on 张志明</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://example.com/tags/golang/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>优先队列</title>
      <link>https://example.com/p/datastruct/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/datastruct/</guid>
      <description>优先队列 绪论 优先队列也可以称之为堆，分为大根堆和小根堆。堆的用处很多，最常见的也就是所谓的堆排序，可以发现也是利用了树的思想去做的。
也许用图表达更合适。
 image 
 堆：符合以下两个条件之一的完全二叉树：
  根节点的值 ≥ 子节点的值，这样的堆被称之为最大堆，或大顶堆；
  根节点的值 ≤ 子节点的值，这样的堆被称之为最小堆，或小顶堆。
  image 
明确的基础的概念之后可以思考一下堆排序。首先将数列构建成一个大根堆，按照性质大根堆的堆顶一定是数组中最大的元素，所以我们可以每次将堆顶的元素换到最后面去，然后重新构建一次大根堆，以此类推就会得到一个排序好的数组。
初始化堆 首先谈谈如何初始化堆。
 情况1: 一个一个插入元素，依次构建堆 情况2: 将一个数组构建堆  我们可以从下标1开始当做根节点，那么数组的长度为N+1（N为原数组长度）设根节点为i，那么 公式可以得出
 i = 1;
  left = i*2;
  right = left+1;
 不妨思考一下这两种情况的复杂度，空间复杂度来说可以直接给出结论，是 O(1),基本是在原数组构建完全二叉树。那么实际复杂度呢？
第一种情况 思考一个这样的情况（最坏的情况，大根堆），每次插入的元素都是当前序列中最大的元素,由于是数组，那么每次插入都是append在末端。那么会造成什么样的情况呢？
当前节点会沿着树的拓扑一直往上浮，树的度为M，那么树的高度是log M，不妨称之为N，那么意味着当前会在树结构中上浮N次。那么参考这张图
 image 
此时树的高度为3，底层每个节点往上浮动的数量都是当节点的深度,所以在高度为3的的堆每次插入节点最坏的情况就是28，N=13，logn=3~4 最大上浮次数是28（不妨先定义为push的操作是O(logn)）
所以我们可以得出每次插入节点上浮的复杂度O(n*logn)
第二种情况 思考一下，如果初始化就是一个数组的情况下，我们会怎么构建这个堆？莫非还是一个个遍历插入吗？显然不会这样做，会有更聪明的办法。
参考第一种情况，既然自底向上上浮不好，那么下沉呢？我们要的结果是降低复杂度，所以思考一下树的结构会发现，树的深度越深，那么节点的数量越多，这些结果都是上浮那么复杂度会很高，但是如果是下沉，那么最深的节点已经在最深处了，就不需要下沉了。
参考这段代码
func Init(h Interface) { // heapify 	n := h.</description>
    </item>
    
    <item>
      <title>AVL</title>
      <link>https://example.com/p/avl/</link>
      <pubDate>Mon, 25 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/avl/</guid>
      <description>AVL树的核心概念 回到二叉搜索树(BST)他的优点显而易见是查询和插入都相对来说非常的高效，在较为好的情况下可以做到都是logn的操作，n对应为树的size。当然这说的是最好的情况下，如果说最坏的情况，会退化成一个链表，所以延伸出了AVL树，之后还有一个红黑树。
AVL的基本概念 AVL的基本概念是一个根节点（每一个子节点也可以看做是一个根节点），的左子树和右子树的高度相差不超过2。看看下面这个图
 image 
例如左图根节点4，它的左节点3的高度为0，右节点没有索引位-1，高度差的概念是
** 左子节点高度 - 右子节点的高度 = 0 - (-1） = 1**
根节点2，它的左节点1的高度为0，右节点4的高度为1 所以 0 - 1 = - 1
既然知道了AVL的定义，那么查看右图显而易见。对于根节点7的左子树高度是3（2，4，5 | 2，4，3），右子树高度为1（8）
3 - 1 = 2 不符合AVL的定义
AVL的接口 AVL树查询可以完美继承BST，所以需要扩展的接口是插入和删除两个接口
插入接口 首先参考这个图，在插入节点3之前是平衡的AVL，但是插入节点3之后，就失去平衡了，失去平衡的节点就是节点6。
 image 
此时此刻就需要旋转，变成如下这样
 image 
此时此刻就平衡了。没错AVL就是每次插入判断是否高度失衡。如果失去平衡则选择。如何选择失去平衡的节点？参考失衡的图，4没有失去平衡，但是6的左节点为2，右节点为0，这就是失去平衡了。所以旋转点就是根节点6！
旋转的4种情况 旋转的情况在邓公的书中有很好的描述
单旋，分左右
 image 
双旋
 image 
删除接口 删除的情况和插入很像，使用BST的删除接口，删除之后自底向上判断是否失平衡。仔细回想一下，插入一个节点如果失去平衡，在旋转一次之后会恢复平衡，父节点一直沿着根节点的高度不会发生变化，所以只需要旋转一次即可，但是删除操作是删除一个节点，旋转之后高度会-1。缺失高度的情况会沿着链路一直往上蔓延。
但是解决办法就是 当旋转完之后判断父节点是否依旧失平衡
package datastructure type AVLInterface interface { } type AVL struct { BST } func NewAVL(data Data) *AVL { avl := &amp;amp;AVL{*NewBST(data)} avl.</description>
    </item>
    
    <item>
      <title>Mutex演进（2）</title>
      <link>https://example.com/p/mutex2/</link>
      <pubDate>Sun, 13 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/mutex2/</guid>
      <description>Mutex是如何实现的（2） 之前看了Mutex的第一版实现，比较简单，一个flag用来判断是否获取到了锁，其他的goroutine排队获取锁，如果换做是我，我能想到的就是第一版的实现。或许还会思考接下来的goroutine公平一点，不是排队获取锁。
接着看第二版实现，给新的goroutine一些机会，总结来说就是新创建的goroutine肯定在这个时刻是cpu在运行的，所以新的goroutine能拿到锁的话就减少了一些切换的时间，可以在一定程度上提升效率。
给新人机会 type Mutex struct { state int32 sema uint32 } const ( mutexLocked = 1 &amp;lt;&amp;lt; iota // mutex is locked //初始值 1  mutexWoken //初始值 2  mutexWaiterShift = iota //初始值 2  ) 上面定义了一些常量，mutexLocked 表示是否拿到了锁，mutexWoken表示是否是被Unlock唤醒的，mutexWaiterShift 表示还有多少goroutine在等待获取锁，这些状态都是用state这一个int32位的字段去表示的，使用的是位表示，比如最低的1位表示mutexLocked，低位的第二位表示mutexWoken，其他的表示mutexWaiterShift。
其实想看懂第二版就需要对位操作有一定的认识，下面我会详细的解释代码中位操作的含义。
 image-20210727142702392 
Lock func (m *Mutex) Lock() { // Fast path: 幸运case，能够直接获取到锁  if atomic.CompareAndSwapInt32(&amp;amp;m.state, 0, mutexLocked) { return } awoke := false for { old := m.</description>
    </item>
    
    <item>
      <title>Mutex演进（1）</title>
      <link>https://example.com/p/mutex1/</link>
      <pubDate>Sat, 12 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/mutex1/</guid>
      <description>Mutex是如何实现的（1） 之前有看一本书上面写了mutex是如何实现的，使用大家都会用，无非就是Lock和Unlock，实现的是Locker接口。在此记录一下Mutex从第一版到现在最新版本是如何实现和演变的。（go 1.16）
什么是Mutex 互斥锁是并发控制的一个手段，为了避免竞争而建立的并发机制，在并发编程中，如果程序中的一部分会被并发的访问或者修改，那么我们就应该考虑使用mutex去保护起来，这部分被保护的区域就是 临界区
Mutex的使用很简单，就像下面这样
var mu sync.Mutex count := 0 go func() { mu.Lock() count += 1 //临界区  mu.Unlock() }() 这里我摘抄一下网上的图片
 image-20210726190116730 
最初的Mutex 介绍完之后就直接看看第一版的Mutex代码，初版的代码只有一个flag表示锁是否被持有，实现也很简单，只需要搞懂原子操作的代码就能看懂（cas），如果flag=1就表示被持有了，如果是0那么锁就会被goroutine们去竞争，抢到的goroutine就会把mutex的flag设置为1，然后继续执行临界区的代码。
 // CAS操作，当时还没有抽象出atomic包 func cas(val *int32, old, new int32) bool func semacquire(*int32) //阻塞 func semrelease(*int32) //唤醒 // 互斥锁的结构，包含两个字段 type Mutex struct { key int32 // 锁是否被持有的标识 sema int32 // 信号量专用，用以阻塞/唤醒goroutine } // 保证成功在val上增加delta的值 func xadd(val *int32, delta int32) (new int32) { for { v := *val //保存v的值 if cas(val, v, v+delta) { //cas操作，比较val和之前保存的v是否有变更 如果没有变更则把val设置为新的值 return v + delta } } panic(&amp;quot;unreached&amp;quot;) } // 请求锁 func (m *Mutex) Lock() { if xadd(&amp;amp;m.</description>
    </item>
    
  </channel>
</rss>
